{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "import random\n",
    "import resize_image\n",
    "import cv2\n",
    "import shutil\n",
    "import collections \n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "import keras\n",
    "from keras.models import load_model,Sequential\n",
    "from keras.initializers import glorot_normal\n",
    "from keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Reshape\n",
    "\n",
    "from resources.data_utils import DataGenerator\n",
    "from resources.utils import prediction_standardized,img_resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the ML model\n",
    "def build_model(nb_classes: int, image_length, seed=25):\n",
    "    initializer = glorot_normal(seed=seed)\n",
    "    model = Sequential()\n",
    "    model.add(Reshape((image_length, image_length, 1), input_shape=(image_length, image_length,)))\n",
    "\n",
    "    model.add(\n",
    "        Conv2D(64, kernel_size=(5, 5), padding='same', kernel_initializer=initializer))\n",
    "    model.add(MaxPooling2D(pool_size=(10, 10)))  \n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(\n",
    "        Conv2D(128, kernel_size=(5, 5), padding='same', kernel_initializer=initializer))\n",
    "    model.add(MaxPooling2D(pool_size=(8, 8)))  \n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Reshape((128 * 1 * 1,), input_shape=(1, 1, 128)))\n",
    "    model.add(Dense(50, activation='relu', kernel_initializer=initializer))\n",
    "    model.add(Dense(nb_classes, activation='softmax', kernel_initializer=initializer))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_label_to_decimal(labels: np.ndarray) -> np.ndarray:\n",
    "    \"\"\" Turns a list of binary vectors to their decimal format.\"\"\"\n",
    "    output = np.zeros(labels.shape[0])\n",
    "    for i, x in enumerate(labels):\n",
    "        output[i] = np.argmax(x)+1\n",
    "    return output.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize the pattern images to 80*80 before training/testing\n",
    "def resize_image(input_dir, out_path, image_size, image_prefix):\n",
    "    image_names = [name for name in os.listdir(input_dir) if name.startswith(image_prefix)]\n",
    "    for image_name in tqdm(image_names, total=len(image_names), desc=\"Resizing images\"):\n",
    "        img_resize(in_path=path_extract + image_name, out_path=path_prepocessed + image_name, image_size=image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_vote(predictions_dec,n):\n",
    "    predictions_mv = []\n",
    "    text_length = int(len(predictions_dec)/n)\n",
    "    for i in range(0,text_length):\n",
    "        n_pred = []\n",
    "        for j in range(0,n):\n",
    "            pred = predictions_dec[j*text_length+i]\n",
    "            n_pred.append(pred)\n",
    "        mv = collections.Counter(n_pred).most_common()[0][0]\n",
    "        predictions_mv.append(mv)\n",
    "    return predictions_mv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract images from video\n",
    "path =  'dataset_keyboard_127/'\n",
    "path_extract = path+'extract/'\n",
    "path_prepocessed = path+\"preprocessed_80/\"\n",
    "\n",
    "# If folder exists, remove it first, then create an empty folder\n",
    "# So there isn't image from previous trials \n",
    "shutil.rmtree(path_extract)\n",
    "os.mkdir(path_extract)\n",
    "shutil.rmtree(path_prepocessed)\n",
    "os.mkdir(path_prepocessed)\n",
    "\n",
    "video_name = 'pattern_video.mp4'\n",
    "# Open the video, extract and save the images\n",
    "cap = cv2.VideoCapture(path+video_name)\n",
    "\n",
    "i=1\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret == False:\n",
    "        break\n",
    "    frame_gs = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    cv2.imwrite(path_extract+str(i)+'.jpg',frame_gs)\n",
    "    i+=1\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resizing images: 100%|██████████| 5010/5010 [00:15<00:00, 318.32it/s]\n"
     ]
    }
   ],
   "source": [
    "# preprocess the images\n",
    "image_size = 80\n",
    "image_prefix = ''\n",
    "resize_image(path_extract, path_prepocessed, image_size, image_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model\n",
    "model = build_model(nb_classes=127, image_length = 80)\n",
    "path_model = path + 'trained_model_1.h5' # where the trianed model is stored\n",
    "model = load_model(path_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all extracted, preprocessed images\n",
    "img_arr = os.listdir(path_prepocessed)\n",
    "img_arr_sorted = sorted(img_arr,key=lambda x: int(os.path.splitext(x)[0]))\n",
    "\n",
    "decoded_text = []\n",
    "img_arr_full = []\n",
    "\n",
    "for img_name in img_arr_sorted:\n",
    "    img_path = path_prepocessed + img_name\n",
    "    img_arr_full.append(img_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the true labels, i.e. the original text\n",
    "text = 'Dynamical systems often generate distinct outputs according to different initial conditions, and one could infer the corresponding input configuration given an output. This property captures the essence of information encoding and decoding. Here, we demonstrate the use of self-organized patterns, combined with machine learning, to achieve distributed information encoding and decoding. Our approach exploits a critical property of many natural pattern-formation systems: in repeated realizations, each initial configuration generates similar but not identical output patterns due to randomness in the patterning process. However, for sufficiently small randomness, groups of patterns that each corresponds to a unique initial configuration can be distinguished from one another. Modulating the pattern generation and machine learning model training can tune the tradeoff between encoding capacity and security. Our method is applicable for a wide variety of self-organized pattern-formation systems. ' # The text to encode in patterns\n",
    "splitted_text = [char for char in text]\n",
    "\n",
    "# create dictionaries for converting the text into numeric representations\n",
    "keyboard = string.printable\n",
    "keyboard = [char for char in keyboard]\n",
    "keyboard = keyboard[0:-5]\n",
    "keyboard_dict = dict(zip(keyboard, np.linspace(1,len(keyboard)+1,len(keyboard)+1).astype(int)))\n",
    "keyboard_dict_r = dict(zip(np.linspace(1,len(keyboard)+1,len(keyboard)+1).astype(int),keyboard))\n",
    "\n",
    "main_labels = [] #the numeric representation of the original text\n",
    "for i in splitted_text:\n",
    "    splitted_text_dec = keyboard_dict.get(i)\n",
    "    main_labels.append(splitted_text_dec)\n",
    "    \n",
    "n = 5 # number of video repeats\n",
    "main_labels_n = main_labels*n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jialu/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9970059880239521\n",
      "The original text:\n",
      "Dynamical systems often generate distinct outputs according to different initial conditions, and one could infer the corresponding input configuration given an output. This property captures the essence of information encoding and decoding. Here, we demonstrate the use of self-organized patterns, combined with machine learning, to achieve distributed information encoding and decoding. Our approach exploits a critical property of many natural pattern-formation systems: in repeated realizations, each initial configuration generates similar but not identical output patterns due to randomness in the patterning process. However, for sufficiently small randomness, groups of patterns that each corresponds to a unique initial configuration can be distinguished from one another. Modulating the pattern generation and machine learning model training can tune the tradeoff between encoding capacity and security. Our method is applicable for a wide variety of self-organized pattern-formation systems. \n",
      "The predicted text:\n",
      "Dynamical systems often genurate distinct outputs according to different initial conditions, and one could infer the corresponding input configuration given an output. This property captures the essence of information encoding and decoding. Here, we demonstrate the use of self-organized patterns, combined with machine learning, to achieve distributed information encoding and decoding. Our approach exploits a>critical property of many natural pattern-formation systems: in repeated realizations, each initial configuration generates similar but not identical output patterns due to randomness in the patterning process. However, for sufficiently small randomness, groups of patterns that each corrcsponds to a unique initial configuration can be distinguished from one another. Modulating the pattern generation and machine learning model training can tune the tradeoff between encoding capacity and security. Our method is applicable for a wide variety of self-organized pattern-formation systems. \n",
      "2 characters were predicted wrong\n"
     ]
    }
   ],
   "source": [
    "# Get the decoded text \n",
    "df_video = pd.DataFrame({\"img_path\": img_arr_full, \"label\": main_labels_n})\n",
    "generation_params = {\"dim\": (80,80),\"nb_classes\": 127,\"column_img\": \"img_path\",\"column_label\": \"label\"}\n",
    "test_generator = DataGenerator(data_frame=df_video, batch_size=len(img_arr_full), shuffle=False, **generation_params)\n",
    "predictions = model.predict_generator(generator=test_generator)\n",
    "predictions_dec = binary_label_to_decimal(prediction_standardized(predictions))\n",
    "predictions_mv = majority_vote(predictions_dec,n)\n",
    "\n",
    "# Compute accuracy\n",
    "acc_test = accuracy_score(main_labels, predictions_mv)\n",
    "print(acc_test)\n",
    "\n",
    "predited_text_mv = ''\n",
    "for i in predictions_mv:\n",
    "    if i>len(keyboard_dict_r):\n",
    "        t = '*' #to indicate predictions beyond the printable characters\n",
    "    else:\n",
    "        t = keyboard_dict_r[i]\n",
    "    predited_text_mv=predited_text_mv+t\n",
    "    \n",
    "print(\"The original text:\")\n",
    "print(text)\n",
    "print(\"The predicted text:\")\n",
    "print(predited_text_mv) # display this on the website\n",
    "n_error = int((1-acc_test)*len(text))\n",
    "print(str(n_error)+\" characters were predicted wrong\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
